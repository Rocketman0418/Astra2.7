{
  "name": "Astra - Data Store Agent (NEW)",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// Simplified classification for Google Drive files only (no Gmail)\nconst crypto = require('crypto');\nconst processedItems = [];\n\nconsole.log('=== CONTENT CLASSIFICATION (Drive Only) ===');\nconsole.log(`Input items: ${$input.all().length}`);\n\nfor (const item of $input.all()) {\n  const data = item.json;\n  \n  // All items are Google Drive files now (no Gmail)\n  if (!data.file_name || !data.file_id) {\n    console.log(`Skipping item with missing file data`);\n    continue;\n  }\n  \n  const contentForHash = data.file_name + \n                         (data.modified_time || '') + \n                         (data.version || '') + \n                         data.team_id; // Include team_id in hash\n  \n  const contentHash = crypto.createHash('md5')\n    .update(contentForHash)\n    .digest('hex');\n  \n  const classification = {\n    source_type: 'google_drive',\n    source_id: data.file_id,\n    title: data.file_name,\n    content_hash: contentHash,\n    modified_time: data.modified_time,\n    should_process: true,\n    is_recent: true,\n    folder_type: data.folder_type, // Pass through folder type\n    team_id: data.team_id // Pass through team_id\n  };\n  \n  processedItems.push({\n    ...data,\n    classification: classification\n  });\n  \n  console.log(`Classified: ${data.file_name} (${data.folder_type}, team: ${data.team_id})`);\n}\n\nconsole.log(`=== CLASSIFICATION RESULTS ===`);\nconsole.log(`Processed ${processedItems.length} Google Drive files`);\n\nreturn processedItems.map(item => ({ json: item }));\n"
      },
      "id": "b1adc289-0237-4ed3-801e-6997180bab6d",
      "name": "Enhanced Content Classification",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        176,
        -496
      ],
      "alwaysOutputData": false
    },
    {
      "parameters": {
        "jsCode": "// Fast hash-based deduplication - no database queries needed\nconst crypto = require('crypto');\nconsole.log('=== FAST HASH DEDUPLICATION ===');\n\nconst contentToProcess = $input.all();\nconsole.log(`Input items: ${contentToProcess.length}`);\n\n// Since we're using time filtering, we expect minimal duplicates\n// Use content hash for edge case protection\nconst seenHashes = new Set();\nconst newContent = [];\nconst duplicates = [];\n\nfor (const item of contentToProcess) {\n  const data = item.json;\n  const classification = data.classification;\n  \n  if (!classification || !classification.should_process) {\n    console.log(`Skipping: ${classification?.title || 'unknown'} - not marked for processing`);\n    continue;\n  }\n  \n  // Create enhanced hash including source info\n  const enhancedHash = crypto.createHash('md5')\n    .update(`${classification.source_type}:${classification.source_id}:${classification.modified_time}`)\n    .digest('hex');\n  \n  if (seenHashes.has(enhancedHash)) {\n    duplicates.push({\n      title: classification.title,\n      hash: enhancedHash.substring(0, 8)\n    });\n    console.log(`Duplicate detected: ${classification.title}`);\n    continue;\n  }\n  \n  seenHashes.add(enhancedHash);\n  newContent.push({\n    ...data,\n    processing_hash: enhancedHash,\n    processing_timestamp: new Date().toISOString()\n  });\n  \n  console.log(`Added: ${classification.title} (${classification.source_type})`);\n}\n\nconsole.log(`=== DEDUPLICATION RESULTS ===`);\nconsole.log(`New items: ${newContent.length}`);\nconsole.log(`Duplicates found: ${duplicates.length}`);\n\nif (newContent.length === 0) {\n  console.log('No new content to process - workflow complete');\n  return [];\n}\n\nreturn newContent.map(item => ({ json: item }));"
      },
      "id": "3cc54731-5f78-4071-8555-080f00f5886a",
      "name": "Fast Hash Deduplication",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        352,
        -496
      ]
    },
    {
      "parameters": {
        "jsCode": "// Document preparation with team_id and folder_type\nconst crypto = require('crypto');\nconst results = [];\n\nfor (const item of $input.all()) {\n  const data = item.json;\n  \n  if (!data.data || typeof data.data !== 'string' || data.data.length < 50) {\n    console.log('Skipping item - no content found');\n    continue;\n  }\n  \n  const content = data.data;\n  const batch_id = crypto.randomUUID();\n  \n  // Use actual file name\n  const actualTitle = data.file_name || data.name || 'Google Drive Document';\n  \n  // Determine document type based on folder\n  let docType = data.folder_type === 'meetings' ? 'misc_meetings' : 'key_strategy';\n  \n  console.log(`Preparing: ${actualTitle} (${data.folder_type}, team: ${data.team_id}, batch_id: ${batch_id})`);\n  \n  const document = {\n    source_type: 'google_drive',\n    source_id: data.file_id || data.id,\n    document_type: docType,\n    title: actualTitle.substring(0, 500),\n    content: content,\n    batch_id: batch_id,\n    team_id: data.team_id, // ← NEW\n    user_id: data.user_id, // ← NEW\n    folder_type: data.folder_type, // ← NEW (meetings or strategy)\n    content_hash: crypto.createHash('md5').update(content.substring(0, 500)).digest('hex'),\n    processing_timestamp: new Date().toISOString(),\n    workflow_id: $workflow.id?.substring(0, 100),\n    execution_id: $execution.id?.substring(0, 100),\n    priority: 'medium',\n    metadata: {\n      content_length: content.length,\n      word_count: content.split(/\\s+/).filter(w => w.length > 0).length,\n      file_name: actualTitle,\n      original_name: data.name,\n      mime_type: data.mime_type || data.mimeType,\n      processing_hash: data.processing_hash,\n      original_version: data.version,\n      batch_id: batch_id,\n      team_id: data.team_id, // ← NEW\n      folder_type: data.folder_type, // ← NEW\n      modified_time: data.modified_time || data.modifiedTime\n    }\n  };\n  \n  results.push(document);\n  console.log(`Prepared: ${document.title} (${content.length} chars, type: ${document.document_type})`);\n}\n\nconsole.log(`Prepared ${results.length} documents for storage`);\nreturn results.map(item => ({ json: item }));\n"
      },
      "id": "fefc3b49-5999-41e3-95d2-1ed13987aeaa",
      "name": "Prepare Documents",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -224,
        -256
      ]
    },
    {
      "parameters": {
        "tableId": "documents",
        "dataToSend": "autoMapInputData"
      },
      "id": "25605854-6901-4b85-94fd-505a856ee5b1",
      "name": "Store Documents (UPSERT)",
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        96,
        -48
      ],
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      },
      "continueOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Optimized chunking with smart sentence boundaries - WITH team_id\nconst chunks = [];\nconst chunkSize = 1000;\nconst overlap = 200;\n\nfor (const item of $input.all()) {\n  const doc = item.json;\n  const content = doc.content;\n  \n  if (!content || content.length < 100) {\n    console.log(`Skipping chunking for ${doc.title} - content too short`);\n    continue;\n  }\n  \n  // Smart chunking at sentence boundaries\n  const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0);\n  let currentChunk = '';\n  let chunkIndex = 0;\n  \n  for (const sentence of sentences) {\n    const trimmedSentence = sentence.trim();\n    if (!trimmedSentence) continue;\n    \n    // Check if adding this sentence would exceed chunk size\n    if (currentChunk.length + trimmedSentence.length > chunkSize && currentChunk.length > 0) {\n      // Save current chunk\n      chunks.push({\n        content: currentChunk.trim(),\n        chunk_index: chunkIndex,\n        source_id: doc.source_id,\n        source_type: doc.source_type,\n        title: doc.title,\n        batch_id: doc.batch_id,\n        team_id: doc.team_id, // ← NEW\n        user_id: doc.user_id, // ← NEW\n        folder_type: doc.folder_type, // ← NEW\n        processing_timestamp: doc.processing_timestamp,\n        metadata: {\n          ...doc.metadata,\n          team_id: doc.team_id, // ← NEW\n          folder_type: doc.folder_type // ← NEW\n        }\n      });\n      \n      // Start new chunk with overlap\n      const words = currentChunk.split(' ');\n      const overlapWords = words.slice(-Math.floor(overlap / 5));\n      currentChunk = overlapWords.join(' ') + ' ' + trimmedSentence;\n      chunkIndex++;\n    } else {\n      currentChunk += (currentChunk ? '. ' : '') + trimmedSentence;\n    }\n  }\n  \n  // Add final chunk\n  if (currentChunk.trim().length > 0) {\n    chunks.push({\n      content: currentChunk.trim(),\n      chunk_index: chunkIndex,\n      source_id: doc.source_id,\n      source_type: doc.source_type,\n      title: doc.title,\n      batch_id: doc.batch_id,\n      team_id: doc.team_id, // ← NEW\n      user_id: doc.user_id, // ← NEW\n      folder_type: doc.folder_type, // ← NEW\n      processing_timestamp: doc.processing_timestamp,\n      metadata: {\n        ...doc.metadata,\n        team_id: doc.team_id, // ← NEW\n        folder_type: doc.folder_type // ← NEW\n      }\n    });\n  }\n}\n\nconsole.log(`Created ${chunks.length} chunks for embedding`);\n\nif (chunks.length === 0) {\n  console.log('No chunks created - ending workflow');\n  return [];\n}\n\nreturn chunks.map(chunk => ({ json: chunk }));\n"
      },
      "id": "f70b97cf-5b40-4081-b52f-7f53f816fcdb",
      "name": "Chunk Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        32,
        -256
      ]
    },
    {
      "parameters": {
        "jsCode": "// Prepare vector chunks with team_id and folder_type\nconst vectorChunks = [];\n\nfunction safeGetNodeData(nodeName) {\n  try {\n    return $(nodeName).all();\n  } catch (error) {\n    console.log(`Warning: Could not access node \"${nodeName}\": ${error.message}`);\n    return [];\n  }\n}\n\nconst chunkDataArray = safeGetNodeData('Chunk Content');\nconst embeddingDataArray = safeGetNodeData('Generate OpenAI Embeddings1') || \n                           safeGetNodeData('Generate OpenAI Embeddings');\n\nconsole.log(`Available chunks: ${chunkDataArray.length}`);\nconsole.log(`Available embeddings: ${embeddingDataArray.length}`);\n\nconst maxItems = Math.min(chunkDataArray.length, embeddingDataArray.length);\n\nif (maxItems === 0) {\n  console.log('No matching chunk/embedding data found');\n  return [];\n}\n\nfor (let i = 0; i < maxItems; i++) {\n  const chunkData = chunkDataArray[i]?.json;\n  const embeddingData = embeddingDataArray[i]?.json;\n  \n  if (!chunkData || !embeddingData?.data?.[0]?.embedding) {\n    console.log(`Skipping chunk ${i} - missing data or embedding`);\n    continue;\n  }\n\n  // Get document type from folder_type\n  let documentType = chunkData.folder_type === 'meetings' ? 'Meetings' : 'Strategy';\n\n  // Extract title and date\n  let documentTitle = chunkData.title || chunkData.metadata?.file_name || 'Unknown Document';\n  let documentDate = chunkData.metadata?.modified_time || new Date().toISOString();\n\n  // Clean and truncate title\n  documentTitle = documentTitle.trim().substring(0, 500);\n\n  // Ensure documentDate is a valid ISO string\n  try {\n    if (documentDate && !documentDate.endsWith('Z') && !documentDate.includes('+')) {\n      documentDate = new Date(documentDate).toISOString();\n    }\n  } catch (error) {\n    console.log(`Warning: Invalid date format, using current time: ${error.message}`);\n    documentDate = new Date().toISOString();\n  }\n\n  // Extract batch_id and team_id\n  const batch_id = chunkData.batch_id || chunkData.metadata?.batch_id;\n  const team_id = chunkData.team_id || chunkData.metadata?.team_id;\n  \n  if (!batch_id) {\n    console.log(`WARNING: Chunk ${i} missing batch_id!`);\n  }\n  \n  if (!team_id) {\n    console.log(`WARNING: Chunk ${i} missing team_id!`);\n  }\n\n  // Create metadata for storage\n  const metadataForDB = {\n    document_name: documentTitle,\n    chunk_index: chunkData.chunk_index,\n    document_type: documentType,\n    source_type: chunkData.source_type,\n    source_id: chunkData.source_id,\n    processing_timestamp: chunkData.processing_timestamp,\n    document_date: documentDate,\n    batch_id: batch_id,\n    team_id: team_id, // ← NEW\n    folder_type: chunkData.folder_type, // ← NEW\n    ...chunkData.metadata\n  };\n\n  // Format embedding as PostgreSQL vector\n  const embedding = embeddingData.data[0].embedding;\n  \n  if (!Array.isArray(embedding) || embedding.length === 0) {\n    console.log(`Skipping chunk ${i} - invalid embedding format`);\n    continue;\n  }\n\n  const vectorString = `[${embedding.join(',')}]`;\n  \n  console.log(`Preparing chunk ${i}: \"${documentTitle}\" (${chunkData.folder_type}, team: ${team_id})`);\n\n  vectorChunks.push({\n    content: chunkData.content,\n    title: documentTitle,\n    document_date: documentDate,\n    batch_id: batch_id,\n    team_id: team_id, // ← NEW\n    folder_type: chunkData.folder_type, // ← NEW for routing\n    metadata: JSON.stringify(metadataForDB),\n    embedding: vectorString\n  });\n}\n\nconsole.log(`Prepared ${vectorChunks.length} vector chunks with team_id and folder_type`);\n\nif (vectorChunks.length === 0) {\n  console.log('No vector chunks to store');\n  return [];\n}\n\nreturn vectorChunks.map(chunk => ({ json: chunk }));\n"
      },
      "id": "eb2ec24a-5170-457c-b351-a8f1ae315a31",
      "name": "Prepare Vector Chunks - FINAL",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        352,
        -256
      ]
    },
    {
      "parameters": {
        "jsCode": "// Success metrics for multi-tenant workflow\nfunction safeGetNodeData(nodeName) {\n  try {\n    return $(nodeName).all();\n  } catch (error) {\n    console.log(`Node ${nodeName} not executed`);\n    return [];\n  }\n}\n\nconst meetingsStored = safeGetNodeData('Store Vector Chunks - Meetings').length;\nconst strategyStored = safeGetNodeData('Store Vector Chunks - Strategy').length;\nconst totalStored = meetingsStored + strategyStored;\n\nconst executionSummary = {\n  workflow_name: 'RocketHub Knowledge - Multi-Tenant',\n  execution_id: $execution.id,\n  completion_time: new Date().toISOString(),\n  status: 'completed_successfully',\n  \n  metrics: {\n    meetings_chunks_stored: meetingsStored,\n    strategy_chunks_stored: strategyStored,\n    total_chunks_stored: totalStored,\n    connections_processed: safeGetNodeData('Loop Over Each Connection').length\n  },\n  \n  business_impact: {\n    knowledge_base_growth: totalStored > 0 ? 'positive' : 'neutral',\n    ai_context_enhanced: totalStored > 0,\n    multi_tenant_support: true\n  }\n};\n\nconsole.log('Multi-Tenant Workflow Completed!');\nconsole.log('Final Metrics:', JSON.stringify(executionSummary, null, 2));\n\nreturn [{ json: executionSummary }];\n"
      },
      "id": "81f4f69e-569c-4102-a5d5-10425a4d8621",
      "name": "Success Metrics & Logging",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1456,
        96
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "=input",
              "value": "={{ $json.content }}"
            },
            {
              "name": "model",
              "value": "text-embedding-3-small"
            }
          ]
        },
        "options": {}
      },
      "id": "be94cc3a-2d98-43ea-81b9-05d9192d9640",
      "name": "Generate OpenAI Embeddings1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        176,
        -256
      ],
      "retryOnFail": true,
      "credentials": {
        "openAiApi": {
          "id": "rAHjtwJ6H3mdRoPS",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "content": "## Astra - Data Store Agent\nJob Description: Capture and store all important company data to our Vector Stores for Astra Intelligence Agent retrieval",
        "height": 112,
        "width": 416,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1456,
        -352
      ],
      "id": "f9d3dddc-9339-489e-bd6e-8e2c28eb3155",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -1488,
        -96
      ],
      "id": "ad74d7f0-edb4-4c4f-b575-744fcf2bac3e",
      "name": "1 Hour"
    },
    {
      "parameters": {
        "jsCode": "// Preserve Google Drive metadata after HTTP Request\nconst processedGoogleDocs = [];\n\n// Get original Google Drive file data\nconst originalFiles = $('Enhanced Content Classification').all();\n\n// Get the HTTP response data (downloaded text content)\nconst httpResponses = $input.all();\n\nconsole.log(`Original files: ${originalFiles.length}`);\nconsole.log(`HTTP responses: ${httpResponses.length}`);\n\n// Match HTTP responses with original metadata\nfor (let i = 0; i < httpResponses.length; i++) {\n  const httpResponse = httpResponses[i];\n  const originalFile = originalFiles[i]?.json;\n  \n  if (!originalFile) {\n    console.log(`Warning: No original file data found for HTTP response ${i}`);\n    continue;\n  }\n  \n  // Get the downloaded content\n  let downloadedContent = '';\n  if (httpResponse.json && typeof httpResponse.json === 'string') {\n    downloadedContent = httpResponse.json;\n  } else if (httpResponse.json && httpResponse.json.data) {\n    downloadedContent = httpResponse.json.data;\n  } else if (httpResponse.binary && httpResponse.binary.data) {\n    downloadedContent = httpResponse.binary.data.toString();\n  }\n  \n  if (!downloadedContent || downloadedContent.length < 10) {\n    console.log(`Warning: No content downloaded for file: ${originalFile.file_name || originalFile.name}`);\n    continue;\n  }\n  \n  // Combine downloaded content with original metadata (including team_id)\n  const combinedData = {\n    ...originalFile, // Includes team_id, user_id, folder_type\n    data: downloadedContent,\n    content_length: downloadedContent.length,\n    download_timestamp: new Date().toISOString(),\n    processing_step: 'content_downloaded'\n  };\n  \n  processedGoogleDocs.push(combinedData);\n  \n  console.log(`Combined: ${originalFile.file_name || originalFile.name} (${downloadedContent.length} chars, team: ${originalFile.team_id}, type: ${originalFile.folder_type})`);\n}\n\nconsole.log(`Successfully processed ${processedGoogleDocs.length} Google Drive documents with preserved metadata`);\n\nreturn processedGoogleDocs.map(doc => ({ json: doc }));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -368,
        -256
      ],
      "id": "2ae0e9bc-f1c4-4e30-a644-8fd145773d76",
      "name": "Metadata"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -1136,
        -96
      ],
      "id": "2f600c5a-78a9-4baf-9d6a-ae491253f023",
      "name": "Loop Over Each Connection"
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "user_drive_connections",
        "returnAll": true,
        "filters": {
          "conditions": [
            {
              "keyName": "is_active",
              "condition": "eq",
              "keyValue": "true"
            },
            {
              "keyName": "connection_status",
              "condition": "eq",
              "keyValue": "connected"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        -1312,
        -96
      ],
      "id": "54f12e0c-348c-4c06-ba64-fe4860988ded",
      "name": "Get Active Drive Connections",
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      }
    },
    {
      "parameters": {
        "url": "https://www.googleapis.com/drive/v3/files",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "q",
              "value": "='{{ $json.meetings_folder_id }}' in parents and (mimeType='application/vnd.google-apps.document' or mimeType='application/pdf') and trashed=false\n\n\n\n\n"
            },
            {
              "name": "fields",
              "value": "files(id,name,mimeType,modifiedTime,webViewLink,size)"
            },
            {
              "name": "pageSize",
              "value": "100"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $json.access_token }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -960,
        224
      ],
      "id": "1d024c0b-7de3-4b44-9961-0ab063642252",
      "name": "Get Files from Meetings Folder"
    },
    {
      "parameters": {
        "url": "https://www.googleapis.com/drive/v3/files",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "q",
              "value": "='{{ $json.strategy_folder_id }}' in parents and (mimeType='application/vnd.google-apps.document' or mimeType='application/pdf') and trashed=false\n"
            },
            {
              "name": "fields",
              "value": "files(id,name,mimeType,modifiedTime,webViewLink,size)"
            },
            {
              "name": "pageSize",
              "value": "100"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $json.access_token }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -944,
        48
      ],
      "id": "b0c81c77-4430-4265-9246-93465aa24fe2",
      "name": "Get Files from Strategy Folder"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -752,
        -96
      ],
      "id": "b9128c52-1dde-4064-bbec-d74304fe59a0",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "// Tag each file with team context from the loop\nconst items = $input.all();\nconst results = [];\n\nconsole.log(`Processing ${items.length} files from merge`);\n\nfor (const item of items) {\n  // Handle both direct files array and nested structure\n  let files = [];\n  \n  if (item.json.files && Array.isArray(item.json.files)) {\n    files = item.json.files;\n  } else if (Array.isArray(item.json)) {\n    files = item.json;\n  } else {\n    files = [item.json];\n  }\n  \n  // Get team context from the current loop iteration\n  const batchData = $('Loop Over Each Connection').item.json;\n  \n  console.log(`Processing batch for team_id: ${batchData.team_id}`);\n  \n  for (const fileData of files) {\n    // Determine source type by checking which folder this file came from\n    // Check if this came from the meetings or strategy HTTP request\n// Determine folder type based on merge input index\n// Input 0 = Strategy Folder, Input 1 = Meetings Folder\nconst mergeInputIndex = item.pairedItem?.index ?? 0;\nconst sourceType = mergeInputIndex === 1 ? 'meetings' : 'strategy';\n\n    \n    results.push({\n      json: {\n        file_id: fileData.id,\n        file_name: fileData.name,\n        mime_type: fileData.mimeType,\n        modified_time: fileData.modifiedTime,\n        web_view_link: fileData.webViewLink,\n        size: fileData.size || 0,\n        team_id: batchData.team_id,\n        user_id: batchData.user_id,\n        source_type: sourceType, // 'meetings' or 'strategy'\n        folder_type: sourceType, // For later routing\n        access_token: batchData.access_token,\n        parent_folder_id: sourceType === 'meetings' \n          ? batchData.meetings_folder_id \n          : batchData.strategy_folder_id,\n        // Keep original data for compatibility\n        id: fileData.id,\n        name: fileData.name,\n        mimeType: fileData.mimeType,\n        modifiedTime: fileData.modifiedTime,\n        version: fileData.version\n      }\n    });\n  }\n}\n\nconsole.log(`Tagged ${results.length} files with team metadata`);\nreturn results;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -608,
        -496
      ],
      "id": "ea771684-d045-43a8-8b79-a8e8136c21f3",
      "name": "Add Team Metadata"
    },
    {
      "parameters": {
        "jsCode": "// Check which files are new/updated\nconst supabase = require('@supabase/supabase-js');\nconst supabaseUrl = process.env.SUPABASE_URL;\nconst supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;\nconst client = supabase.createClient(supabaseUrl, supabaseKey);\n\nconst files = $input.all();\nconst newFiles = [];\n\nfor (const item of files) {\n  const file = item.json;\n  const table = file.source_type === 'meetings' \n    ? 'document_chunks_meetings' \n    : 'document_chunks_strategy';\n  \n  // Check if file already exists with same modified_time\n  const { data: existing } = await client\n    .from(table)\n    .select('id, document_date')\n    .eq('team_id', file.team_id)\n    .contains('metadata', { source_id: file.file_id })\n    .limit(1);\n  \n  if (!existing || existing.length === 0) {\n    console.log(`New file: ${file.file_name}`);\n    newFiles.push(file);\n  } else {\n    const existingDate = new Date(existing[0].document_date);\n    const fileDate = new Date(file.modified_time);\n    \n    if (fileDate > existingDate) {\n      console.log(`Updated file: ${file.file_name}`);\n      newFiles.push(file);\n    } else {\n      console.log(`Skipping unchanged file: ${file.file_name}`);\n    }\n  }\n}\n\nconsole.log(`Processing ${newFiles.length} new/updated files`);\nreturn newFiles.map(f => ({ json: f }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1568,
        352
      ],
      "id": "0d03a4e3-fb4e-47c6-92cd-2d9736dfeca3",
      "name": "Filter Already Processed"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO document_chunks_meetings (\n  content, title, document_date, batch_id, team_id, metadata, embedding\n) \nVALUES (\n  $1, $2, $3::timestamp, $4::uuid, $5::uuid, $6::jsonb, $7::vector\n) \nON CONFLICT ON CONSTRAINT document_chunks_pkey \nDO UPDATE SET \n  content = EXCLUDED.content, \n  title = EXCLUDED.title,\n  document_date = EXCLUDED.document_date,\n  batch_id = EXCLUDED.batch_id,\n  team_id = EXCLUDED.team_id,\n  metadata = EXCLUDED.metadata, \n  embedding = EXCLUDED.embedding, \n  updated_at = NOW() \nRETURNING id\n",
        "options": {
          "queryReplacement": "=={{ $json.content }}, {{ $json.title }}, {{ $json.document_date }}, {{ $json.batch_id }}, {{ $json.team_id }}, {{ $json.metadata }}, {{ $json.embedding }}"
        }
      },
      "id": "cce7cf4b-abac-4333-bd71-9cb1d874b7ba",
      "name": "Store Vector Chunks - Meetings",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [
        720,
        -240
      ],
      "credentials": {
        "postgres": {
          "id": "kEtmOjsypxatQPLu",
          "name": "Postgres RocketHub"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO document_chunks_strategy (\n  content, title, document_date, batch_id, team_id, metadata, embedding\n) \nVALUES (\n  $1, $2, $3::timestamp, $4::uuid, $5::uuid, $6::jsonb, $7::vector\n) \nON CONFLICT ON CONSTRAINT document_chunks_strategy_title_content_hash_key \nDO UPDATE SET \n  content = EXCLUDED.content, \n  title = EXCLUDED.title,\n  document_date = EXCLUDED.document_date,\n  batch_id = EXCLUDED.batch_id,\n  team_id = EXCLUDED.team_id,\n  metadata = EXCLUDED.metadata, \n  embedding = EXCLUDED.embedding, \n  updated_at = NOW() \nRETURNING id\n\n",
        "options": {
          "queryReplacement": "=={{ $json.content }}, {{ $json.title }}, {{ $json.document_date }}, {{ $json.batch_id }}, {{ $json.team_id }}, {{ $json.metadata }}, {{ $json.embedding }}"
        }
      },
      "id": "beeb61a8-a2bc-4b5c-84af-1740011869b5",
      "name": "Store Vector Chunks - Strategy",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [
        720,
        -48
      ],
      "credentials": {
        "postgres": {
          "id": "kEtmOjsypxatQPLu",
          "name": "Postgres RocketHub"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.folder_type }}",
                    "rightValue": "meetings",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "5d8de30b-1646-4cc3-bfc5-08dd54cbebc7"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Meetings"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "db5e6269-6ab0-4e36-ad7b-e8b343c83337",
                    "leftValue": "={{ $json.folder_type }}",
                    "rightValue": "strategy",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Strategy"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        544,
        -256
      ],
      "id": "db203069-1945-429c-84eb-d818681e3b47",
      "name": "Route by Folder Type"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        928,
        -144
      ],
      "id": "27e9a2c3-9af7-46d0-a2d7-a19520a84690",
      "name": "Merge Storage Results"
    },
    {
      "parameters": {
        "jsCode": "// Update last_sync_at for this connection\nconst connectionData = $('Loop Over Each Connection').item.json;\n\n// Count how many chunks were stored\nconst storedCount = $input.all().length;\n\nconsole.log(`Sync complete for connection ${connectionData.id}`);\nconsole.log(`Stored ${storedCount} chunks`);\nconsole.log(`Team: ${connectionData.team_id}`);\n\nreturn [{\n  json: {\n    connection_id: connectionData.id,\n    team_id: connectionData.team_id,\n    user_id: connectionData.user_id,\n    chunks_stored: storedCount,\n    sync_timestamp: new Date().toISOString()\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1104,
        -144
      ],
      "id": "2ce7e73e-07e4-44a2-abda-a36ba12ffae9",
      "name": "Update Sync Statu"
    },
    {
      "parameters": {
        "url": "=https://poquwzvcleazbbdelcsh.supabase.co/rest/v1/document_chunks_meetings\n",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "select",
              "value": "id,document_date,metadata"
            },
            {
              "name": "team_id",
              "value": "=eq.{{ $json.team_id }}"
            },
            {
              "name": "metadata->>source_id",
              "value": "=eq.{{ $json.file_id }}"
            },
            {
              "name": "limit",
              "value": "1"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -384,
        -800
      ],
      "id": "f962f417-7c97-4c1d-8a63-d2a869aa814b",
      "name": "Check Existing - Meetings",
      "alwaysOutputData": true,
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      }
    },
    {
      "parameters": {
        "url": "=https://poquwzvcleazbbdelcsh.supabase.co/rest/v1/document_chunks_strategy\n",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "select",
              "value": "id,document_date,metadata"
            },
            {
              "name": "team_id",
              "value": "=eq.{{ $json.team_id }}"
            },
            {
              "name": "metadata->>source_id",
              "value": "=eq.{{ $json.file_id }}"
            },
            {
              "name": "limit",
              "value": "1"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -384,
        -624
      ],
      "id": "7d881b70-f629-4b20-ba4c-4a8c8d03fcf1",
      "name": "Check Existing - Strategy",
      "alwaysOutputData": true,
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// This node filters out files that already exist in the database\n// and only passes through new files or files that have been modified\n\nconst inputItems = $input.all(); // All 20 files from Add Team Metadata\n\n// Try to get merged results, but handle the case where Merge has no output\nlet existingFilesMap = new Map();\n\ntry {\n  const mergedItems = $('Merge').all();\n  \n  mergedItems.forEach(item => {\n    const sourceId = item.json.metadata?.source_id || item.json.source_id;\n    const docDate = item.json.document_date;\n    \n    if (sourceId && docDate) {\n      existingFilesMap.set(sourceId, docDate);\n    }\n  });\n} catch (error) {\n  // No existing files found - that's OK, all files are new\n  console.log('No existing files found in database');\n}\n\nconsole.log('Existing files found:', existingFilesMap.size);\nconsole.log('Input files to check:', inputItems.length);\n\n// Filter input items - only keep new or updated files\nconst newOrUpdatedFiles = inputItems.filter(item => {\n  const fileId = item.json.file_id;\n  const modifiedTime = item.json.modified_time;\n  \n  // If file doesn't exist in database, it's new\n  if (!existingFilesMap.has(fileId)) {\n    return true;\n  }\n  \n  // If file exists, check if it's been modified\n  const existingDate = existingFilesMap.get(fileId);\n  const fileDate = new Date(modifiedTime);\n  const existingFileDate = new Date(existingDate);\n  \n  return fileDate > existingFileDate;\n});\n\nconsole.log('Files to process:', newOrUpdatedFiles.length);\n\nreturn newOrUpdatedFiles;\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -16,
        -496
      ],
      "id": "deeadadc-2310-4e91-875d-efe8442a42e0",
      "name": "Filter New/Updated Files",
      "alwaysOutputData": true
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -192,
        -736
      ],
      "id": "5fe60d55-9631-4594-a507-7fd212607a36",
      "name": "Merge1"
    },
    {
      "parameters": {
        "url": "=https://www.googleapis.com/drive/v3/files/{{ $json.file_id || $json.id }}/export?mimeType=text/plain\n",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "={{ 'Bearer ' + String($json.access_token).trim() }}\n"
            }
          ]
        },
        "options": {
          "redirect": {
            "redirect": {}
          },
          "response": {
            "response": {
              "responseFormat": "text"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        672,
        -672
      ],
      "id": "d13d781f-010a-44cc-a7e6-6135f048d09d",
      "name": "Download Document Content (old)"
    },
    {
      "parameters": {
        "jsCode": "const items = [];\n\nfor (const item of $input.all()) {\n  const fileId = item.json.file_id || item.json.id;\n  const accessToken = item.json.access_token;\n  const fileName = item.json.name;\n  \n  try {\n    const response = await this.helpers.httpRequest({\n      method: 'GET',\n      url: `https://www.googleapis.com/drive/v3/files/${fileId}/export?mimeType=text/plain`,\n      headers: {\n        'Authorization': `Bearer ${accessToken}`\n      }\n    });\n    \n    items.push({\n      json: {\n        file_id: fileId,\n        file_name: fileName,\n        content: response,\n        access_token: accessToken\n      }\n    });\n  } catch (error) {\n    items.push({\n      json: {\n        file_id: fileId,\n        file_name: fileName,\n        error: error.message,\n        access_token: accessToken\n      }\n    });\n  }\n}\n\nreturn items;\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        560,
        -480
      ],
      "id": "c23aed76-02b1-41e9-aa3d-045862f97bcd",
      "name": "Download Document Content"
    }
  ],
  "pinData": {},
  "connections": {
    "Enhanced Content Classification": {
      "main": [
        [
          {
            "node": "Fast Hash Deduplication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fast Hash Deduplication": {
      "main": [
        [
          {
            "node": "Download Document Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Documents": {
      "main": [
        [
          {
            "node": "Store Documents (UPSERT)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Chunk Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Documents (UPSERT)": {
      "main": [
        [
          {
            "node": "Success Metrics & Logging",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Vector Chunks - FINAL": {
      "main": [
        [
          {
            "node": "Route by Folder Type",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunk Content": {
      "main": [
        [
          {
            "node": "Generate OpenAI Embeddings1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate OpenAI Embeddings1": {
      "main": [
        [
          {
            "node": "Prepare Vector Chunks - FINAL",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "1 Hour": {
      "main": [
        [
          {
            "node": "Get Active Drive Connections",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Metadata": {
      "main": [
        [
          {
            "node": "Prepare Documents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Each Connection": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Get Files from Meetings Folder",
            "type": "main",
            "index": 0
          },
          {
            "node": "Get Files from Strategy Folder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Active Drive Connections": {
      "main": [
        [
          {
            "node": "Loop Over Each Connection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Files from Strategy Folder": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Files from Meetings Folder": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Add Team Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add Team Metadata": {
      "main": [
        [
          {
            "node": "Check Existing - Meetings",
            "type": "main",
            "index": 0
          },
          {
            "node": "Check Existing - Strategy",
            "type": "main",
            "index": 0
          },
          {
            "node": "Filter New/Updated Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter Already Processed": {
      "main": [
        []
      ]
    },
    "Store Vector Chunks - Meetings": {
      "main": [
        [
          {
            "node": "Merge Storage Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route by Folder Type": {
      "main": [
        [
          {
            "node": "Store Vector Chunks - Meetings",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Store Vector Chunks - Strategy",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Vector Chunks - Strategy": {
      "main": [
        [
          {
            "node": "Merge Storage Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Storage Results": {
      "main": [
        [
          {
            "node": "Update Sync Statu",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Sync Statu": {
      "main": [
        [
          {
            "node": "Success Metrics & Logging",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Existing - Meetings": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Existing - Strategy": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Filter New/Updated Files": {
      "main": [
        [
          {
            "node": "Enhanced Content Classification",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Filter New/Updated Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Document Content (old)": {
      "main": [
        []
      ]
    },
    "Download Document Content": {
      "main": [
        [
          {
            "node": "Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "6e24c09e-41bd-4859-b541-fb7d945ad743",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "339010dd32d635dc12d1b22611396aba8fa80f3c41d9792b7d3b5098ba3bdda1"
  },
  "id": "h71aBw6dTxmzQzpk",
  "tags": []
}