{
  "name": "Astra - Multi-Team Data Sync Agent",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// Simplified classification for Google Drive files only (no Gmail)\nconst crypto = require('crypto');\nconst processedItems = [];\n\nconsole.log('=== CONTENT CLASSIFICATION (Drive Only) ===');\nconsole.log(`Input items: ${$input.all().length}`);\n\nfor (const item of $input.all()) {\n  const data = item.json;\n  \n  // All items are Google Drive files now (no Gmail)\n  if (!data.file_name || !data.file_id) {\n    console.log(`Skipping item with missing file data`);\n    continue;\n  }\n  \n  const contentForHash = data.file_name + \n                         (data.modified_time || '') + \n                         (data.version || '') + \n                         data.team_id; // Include team_id in hash\n  \n  const contentHash = crypto.createHash('md5')\n    .update(contentForHash)\n    .digest('hex');\n  \n  const classification = {\n    source_type: 'google_drive',\n    source_id: data.file_id,\n    title: data.file_name,\n    content_hash: contentHash,\n    modified_time: data.modified_time,\n    should_process: true,\n    is_recent: true,\n    folder_type: data.folder_type, // Pass through folder type\n    team_id: data.team_id // Pass through team_id\n  };\n  \n  processedItems.push({\n    ...data,\n    classification: classification\n  });\n  \n  console.log(`Classified: ${data.file_name} (${data.folder_type}, team: ${data.team_id})`);\n}\n\nconsole.log(`=== CLASSIFICATION RESULTS ===`);\nconsole.log(`Processed ${processedItems.length} Google Drive files`);\n\nreturn processedItems.map(item => ({ json: item }));\n"
      },
      "id": "b1adc289-0237-4ed3-801e-6997180bab6d",
      "name": "Enhanced Content Classification",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -32,
        -96
      ],
      "alwaysOutputData": false
    },
    {
      "parameters": {
        "jsCode": "// Fast hash-based deduplication - no database queries needed\nconst crypto = require('crypto');\nconsole.log('=== FAST HASH DEDUPLICATION ===');\n\nconst contentToProcess = $input.all();\nconsole.log(`Input items: ${contentToProcess.length}`);\n\n// Since we're using time filtering, we expect minimal duplicates\n// Use content hash for edge case protection\nconst seenHashes = new Set();\nconst newContent = [];\nconst duplicates = [];\n\nfor (const item of contentToProcess) {\n  const data = item.json;\n  const classification = data.classification;\n  \n  if (!classification || !classification.should_process) {\n    console.log(`Skipping: ${classification?.title || 'unknown'} - not marked for processing`);\n    continue;\n  }\n  \n  // Create enhanced hash including source info\n  const enhancedHash = crypto.createHash('md5')\n    .update(`${classification.source_type}:${classification.source_id}:${classification.modified_time}`)\n    .digest('hex');\n  \n  if (seenHashes.has(enhancedHash)) {\n    duplicates.push({\n      title: classification.title,\n      hash: enhancedHash.substring(0, 8)\n    });\n    console.log(`Duplicate detected: ${classification.title}`);\n    continue;\n  }\n  \n  seenHashes.add(enhancedHash);\n  newContent.push({\n    ...data,\n    processing_hash: enhancedHash,\n    processing_timestamp: new Date().toISOString()\n  });\n  \n  console.log(`Added: ${classification.title} (${classification.source_type})`);\n}\n\nconsole.log(`=== DEDUPLICATION RESULTS ===`);\nconsole.log(`New items: ${newContent.length}`);\nconsole.log(`Duplicates found: ${duplicates.length}`);\n\nif (newContent.length === 0) {\n  console.log('No new content to process - workflow complete');\n  return [];\n}\n\nreturn newContent.map(item => ({ json: item }));"
      },
      "id": "3cc54731-5f78-4071-8555-080f00f5886a",
      "name": "Fast Hash Deduplication",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        144,
        -96
      ]
    },
    {
      "parameters": {
        "jsCode": "// Document preparation with team_id and folder_type\nconst crypto = require('crypto');\nconst results = [];\n\nfor (const item of $input.all()) {\n  const data = item.json;\n  \n  if (!data.data || typeof data.data !== 'string' || data.data.length < 50) {\n    console.log('Skipping item - no content found');\n    continue;\n  }\n  \n  const content = data.data;\n  const batch_id = crypto.randomUUID();\n  \n  // Use actual file name\n  const actualTitle = data.file_name || data.name || 'Google Drive Document';\n  \n  // Determine document type based on folder\n  let docType = data.folder_type === 'meetings' ? 'misc_meetings' : 'key_strategy';\n  \n  console.log(`Preparing: ${actualTitle} (${data.folder_type}, team: ${data.team_id}, batch_id: ${batch_id})`);\n  \n  const document = {\n  source_type: 'google_drive',\n  source_id: data.file_id || data.id,\n  document_type: docType,\n  title: actualTitle.substring(0, 500),\n  content: content,\n  batch_id: batch_id,\n  team_id: data.team_id,\n  user_id: data.user_id,\n  folder_type: data.folder_type,\n  source_modified_time: data.modified_time, // ← ADD THIS LINE\n  content_hash: crypto.createHash('md5').update(content.substring(0, 500)).digest('hex'),\n  processing_timestamp: new Date().toISOString(),\n  workflow_id: $workflow.id?.substring(0, 100),\n  execution_id: $execution.id?.substring(0, 100),\n  priority: 'medium',\n  metadata: {\n    content_length: content.length,\n    word_count: content.split(/\\s+/).filter(w => w.length > 0).length,\n    file_name: actualTitle,\n    original_name: data.name,\n    mime_type: data.mime_type || data.mimeType,\n    processing_hash: data.processing_hash,\n    original_version: data.version,\n    batch_id: batch_id,\n    team_id: data.team_id,\n    folder_type: data.folder_type,\n    modified_time: data.modified_time\n  }\n  };\n  \n  results.push(document);\n  console.log(`Prepared: ${document.title} (${content.length} chars, type: ${document.document_type})`);\n}\n\nconsole.log(`Prepared ${results.length} documents for storage`);\nreturn results.map(item => ({ json: item }));\n"
      },
      "id": "fefc3b49-5999-41e3-95d2-1ed13987aeaa",
      "name": "Prepare Documents",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1296,
        160
      ]
    },
    {
      "parameters": {
        "tableId": "documents",
        "dataToSend": "autoMapInputData"
      },
      "id": "25605854-6901-4b85-94fd-505a856ee5b1",
      "name": "Store Documents (UPSERT)",
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        -880,
        352
      ],
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      },
      "continueOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// Optimized chunking with smart sentence boundaries - WITH team_id\nconst chunks = [];\nconst chunkSize = 1000;\nconst overlap = 200;\n\nfor (const item of $input.all()) {\n  const doc = item.json;\n  const content = doc.content;\n  \n  if (!content || content.length < 100) {\n    console.log(`Skipping chunking for ${doc.title} - content too short`);\n    continue;\n  }\n  \n  // Smart chunking at sentence boundaries\n  const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0);\n  let currentChunk = '';\n  let chunkIndex = 0;\n  \n  for (const sentence of sentences) {\n    const trimmedSentence = sentence.trim();\n    if (!trimmedSentence) continue;\n    \n    // Check if adding this sentence would exceed chunk size\n    if (currentChunk.length + trimmedSentence.length > chunkSize && currentChunk.length > 0) {\n      // Save current chunk\n      chunks.push({\n        content: currentChunk.trim(),\n        chunk_index: chunkIndex,\n        source_id: doc.source_id,\n        source_type: doc.source_type,\n        title: doc.title,\n        batch_id: doc.batch_id,\n        team_id: doc.team_id, // ← NEW\n        user_id: doc.user_id, // ← NEW\n        folder_type: doc.folder_type, // ← NEW\n        processing_timestamp: doc.processing_timestamp,\n        metadata: {\n          ...doc.metadata,\n          team_id: doc.team_id, // ← NEW\n          folder_type: doc.folder_type // ← NEW\n        }\n      });\n      \n      // Start new chunk with overlap\n      const words = currentChunk.split(' ');\n      const overlapWords = words.slice(-Math.floor(overlap / 5));\n      currentChunk = overlapWords.join(' ') + ' ' + trimmedSentence;\n      chunkIndex++;\n    } else {\n      currentChunk += (currentChunk ? '. ' : '') + trimmedSentence;\n    }\n  }\n  \n  // Add final chunk\n  if (currentChunk.trim().length > 0) {\n    chunks.push({\n      content: currentChunk.trim(),\n      chunk_index: chunkIndex,\n      source_id: doc.source_id,\n      source_type: doc.source_type,\n      title: doc.title,\n      batch_id: doc.batch_id,\n      team_id: doc.team_id, // ← NEW\n      user_id: doc.user_id, // ← NEW\n      folder_type: doc.folder_type, // ← NEW\n      processing_timestamp: doc.processing_timestamp,\n      metadata: {\n        ...doc.metadata,\n        team_id: doc.team_id, // ← NEW\n        folder_type: doc.folder_type // ← NEW\n      }\n    });\n  }\n}\n\nconsole.log(`Created ${chunks.length} chunks for embedding`);\n\nif (chunks.length === 0) {\n  console.log('No chunks created - ending workflow');\n  return [];\n}\n\nreturn chunks.map(chunk => ({ json: chunk }));\n"
      },
      "id": "f70b97cf-5b40-4081-b52f-7f53f816fcdb",
      "name": "Chunk Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1040,
        160
      ]
    },
    {
      "parameters": {
        "jsCode": "// Prepare vector chunks with team_id and folder_type\nconst vectorChunks = [];\n\nfunction safeGetNodeData(nodeName) {\n  try {\n    return $(nodeName).all();\n  } catch (error) {\n    console.log(`Warning: Could not access node \"${nodeName}\": ${error.message}`);\n    return [];\n  }\n}\n\nconst chunkDataArray = safeGetNodeData('Chunk Content');\nconst embeddingDataArray = safeGetNodeData('Generate OpenAI Embeddings1') || \n                           safeGetNodeData('Generate OpenAI Embeddings');\n\nconsole.log(`Available chunks: ${chunkDataArray.length}`);\nconsole.log(`Available embeddings: ${embeddingDataArray.length}`);\n\nconst maxItems = Math.min(chunkDataArray.length, embeddingDataArray.length);\n\nif (maxItems === 0) {\n  console.log('No matching chunk/embedding data found');\n  return [];\n}\n\nfor (let i = 0; i < maxItems; i++) {\n  const chunkData = chunkDataArray[i]?.json;\n  const embeddingData = embeddingDataArray[i]?.json;\n  \n  if (!chunkData || !embeddingData?.data?.[0]?.embedding) {\n    console.log(`Skipping chunk ${i} - missing data or embedding`);\n    continue;\n  }\n\n  // Get document type from folder_type\n  let documentType = chunkData.folder_type === 'meetings' ? 'Meetings' : 'Strategy';\n\n  // Extract title and date\n  let documentTitle = chunkData.title || chunkData.metadata?.file_name || 'Unknown Document';\n  let documentDate = chunkData.metadata?.modified_time || new Date().toISOString();\n\n  // Clean and truncate title\n  documentTitle = documentTitle.trim().substring(0, 500);\n\n  // Ensure documentDate is a valid ISO string\n  try {\n    if (documentDate && !documentDate.endsWith('Z') && !documentDate.includes('+')) {\n      documentDate = new Date(documentDate).toISOString();\n    }\n  } catch (error) {\n    console.log(`Warning: Invalid date format, using current time: ${error.message}`);\n    documentDate = new Date().toISOString();\n  }\n\n  // Extract batch_id and team_id\n  const batch_id = chunkData.batch_id || chunkData.metadata?.batch_id;\n  const team_id = chunkData.team_id || chunkData.metadata?.team_id;\n  \n  if (!batch_id) {\n    console.log(`WARNING: Chunk ${i} missing batch_id!`);\n  }\n  \n  if (!team_id) {\n    console.log(`WARNING: Chunk ${i} missing team_id!`);\n  }\n\n  // Create metadata for storage\n  const metadataForDB = {\n    document_name: documentTitle,\n    chunk_index: chunkData.chunk_index,\n    document_type: documentType,\n    source_type: chunkData.source_type,\n    source_id: chunkData.source_id,\n    processing_timestamp: chunkData.processing_timestamp,\n    document_date: documentDate,\n    batch_id: batch_id,\n    team_id: team_id, // ← NEW\n    folder_type: chunkData.folder_type, // ← NEW\n    ...chunkData.metadata\n  };\n\n  // Format embedding as PostgreSQL vector\n  const embedding = embeddingData.data[0].embedding;\n  \n  if (!Array.isArray(embedding) || embedding.length === 0) {\n    console.log(`Skipping chunk ${i} - invalid embedding format`);\n    continue;\n  }\n\n  const vectorString = `[${embedding.join(',')}]`;\n  \n  console.log(`Preparing chunk ${i}: \"${documentTitle}\" (${chunkData.folder_type}, team: ${team_id})`);\n\n  vectorChunks.push({\n    content: chunkData.content,\n    title: documentTitle,\n    document_date: documentDate,\n    batch_id: batch_id,\n    team_id: team_id, // ← NEW\n    folder_type: chunkData.folder_type, // ← NEW for routing\n    metadata: JSON.stringify(metadataForDB),\n    embedding: vectorString\n  });\n}\n\nconsole.log(`Prepared ${vectorChunks.length} vector chunks with team_id and folder_type`);\n\nif (vectorChunks.length === 0) {\n  console.log('No vector chunks to store');\n  return [];\n}\n\nreturn vectorChunks.map(chunk => ({ json: chunk }));\n"
      },
      "id": "eb2ec24a-5170-457c-b351-a8f1ae315a31",
      "name": "Prepare Vector Chunks - FINAL",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -720,
        160
      ]
    },
    {
      "parameters": {
        "jsCode": "// Success metrics for multi-tenant workflow\nfunction safeGetNodeData(nodeName) {\n  try {\n    return $(nodeName).all();\n  } catch (error) {\n    console.log(`Node ${nodeName} not executed`);\n    return [];\n  }\n}\n\nconst meetingsStored = safeGetNodeData('Store Vector Chunks - Meetings').length;\nconst strategyStored = safeGetNodeData('Store Vector Chunks - Strategy').length;\nconst totalStored = meetingsStored + strategyStored;\n\nconst executionSummary = {\n  workflow_name: 'RocketHub Knowledge - Multi-Tenant',\n  execution_id: $execution.id,\n  completion_time: new Date().toISOString(),\n  status: 'completed_successfully',\n  \n  metrics: {\n    meetings_chunks_stored: meetingsStored,\n    strategy_chunks_stored: strategyStored,\n    total_chunks_stored: totalStored,\n    connections_processed: safeGetNodeData('Loop Over Each Connection').length\n  },\n  \n  business_impact: {\n    knowledge_base_growth: totalStored > 0 ? 'positive' : 'neutral',\n    ai_context_enhanced: totalStored > 0,\n    multi_tenant_support: true\n  }\n};\n\nconsole.log('Multi-Tenant Workflow Completed!');\nconsole.log('Final Metrics:', JSON.stringify(executionSummary, null, 2));\n\nreturn [{ json: executionSummary }];\n"
      },
      "id": "81f4f69e-569c-4102-a5d5-10425a4d8621",
      "name": "Success Metrics & Logging",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        336,
        352
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "=input",
              "value": "={{ $json.content }}"
            },
            {
              "name": "model",
              "value": "text-embedding-3-small"
            }
          ]
        },
        "options": {}
      },
      "id": "be94cc3a-2d98-43ea-81b9-05d9192d9640",
      "name": "Generate OpenAI Embeddings1",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -896,
        160
      ],
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 2000,
      "credentials": {
        "openAiApi": {
          "id": "rAHjtwJ6H3mdRoPS",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "content": "## Astra - Multi-Team Data Sync Agent\nJob Description: Capture and store all important company data to our Vector Stores for Astra Intelligence Agent retrieval",
        "height": 176,
        "width": 416,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -1456,
        -352
      ],
      "id": "f9d3dddc-9339-489e-bd6e-8e2c28eb3155",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "hours"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [
        -1488,
        -96
      ],
      "id": "ad74d7f0-edb4-4c4f-b575-744fcf2bac3e",
      "name": "1 Hour"
    },
    {
      "parameters": {
        "jsCode": "// Preserve Google Drive metadata after code-based download\nconst processedGoogleDocs = [];\n\n// The Download Document Content node already combined everything!\n// We just need to pass it through with the right structure\nconst downloadedItems = $input.all();\n\nconsole.log(`Processing ${downloadedItems.length} downloaded items`);\n\nfor (const item of downloadedItems) {\n  const data = item.json;\n  \n  // Check if we have content\n  if (!data.content || data.content.length < 10) {\n    console.log(`Warning: No content for file: ${data.file_name}`);\n    continue;\n  }\n  \n  // The Download node should have preserved the original metadata\n  // We need to get it from the Enhanced Content Classification node\n  const originalFiles = $('Enhanced Content Classification').all();\n  const matchingFile = originalFiles.find(f => \n    (f.json.file_id || f.json.id) === data.file_id\n  );\n  \n  if (!matchingFile) {\n    console.log(`Warning: Could not find original metadata for ${data.file_name}`);\n    continue;\n  }\n  \n  // Combine downloaded content with ALL original metadata\n  const combinedData = {\n    ...matchingFile.json, // ALL original metadata including team_id, folder_type, etc.\n    data: data.content, // The downloaded text content\n    content_length: data.content.length,\n    download_timestamp: new Date().toISOString(),\n    processing_step: 'content_downloaded'\n  };\n  \n  processedGoogleDocs.push(combinedData);\n  \n  console.log(`Combined: ${combinedData.file_name} (${data.content.length} chars, team: ${combinedData.team_id}, type: ${combinedData.folder_type})`);\n}\n\nconsole.log(`Successfully processed ${processedGoogleDocs.length} Google Drive documents with preserved metadata`);\n\nreturn processedGoogleDocs.map(doc => ({ json: doc }));\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1440,
        160
      ],
      "id": "2ae0e9bc-f1c4-4e30-a644-8fd145773d76",
      "name": "Metadata"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -1136,
        -96
      ],
      "id": "2f600c5a-78a9-4baf-9d6a-ae491253f023",
      "name": "Loop Over Each Connection"
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "user_drive_connections",
        "returnAll": true,
        "filters": {
          "conditions": [
            {
              "keyName": "is_active",
              "condition": "eq",
              "keyValue": "true"
            },
            {
              "keyName": "connection_status",
              "condition": "eq",
              "keyValue": "connected"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        -1312,
        -96
      ],
      "id": "54f12e0c-348c-4c06-ba64-fe4860988ded",
      "name": "Get Active Drive Connections",
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      }
    },
    {
      "parameters": {
        "url": "https://www.googleapis.com/drive/v3/files",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "q",
              "value": "='{{ $json.meetings_folder_id }}' in parents and (mimeType='application/vnd.google-apps.document' or mimeType='application/pdf') and trashed=false\n\n\n\n\n"
            },
            {
              "name": "fields",
              "value": "files(id,name,mimeType,modifiedTime,webViewLink,size)"
            },
            {
              "name": "pageSize",
              "value": "100"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $json.access_token }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -944,
        -32
      ],
      "id": "1d024c0b-7de3-4b44-9961-0ab063642252",
      "name": "Get Files from Meetings Folder"
    },
    {
      "parameters": {
        "url": "https://www.googleapis.com/drive/v3/files",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "q",
              "value": "='{{ $json.strategy_folder_id }}' in parents and (mimeType='application/vnd.google-apps.document' or mimeType='application/pdf') and trashed=false\n"
            },
            {
              "name": "fields",
              "value": "files(id,name,mimeType,modifiedTime,webViewLink,size)"
            },
            {
              "name": "pageSize",
              "value": "100"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "=Bearer {{ $json.access_token }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -944,
        -224
      ],
      "id": "b0c81c77-4430-4265-9246-93465aa24fe2",
      "name": "Get Files from Strategy Folder"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -752,
        -96
      ],
      "id": "b9128c52-1dde-4064-bbec-d74304fe59a0",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "// Add team metadata to files from both folders\nconst items = $input.all();\n\nconsole.log(`Processing ${items.length} items from merge`);\n\nconst processedItems = [];\nconst teamId = '72b41e8a-c7bb-4b99-bf98-706b1ca61a76';\n\n// Process each input item (which are the merged responses from both folders)\nfor (const item of items) {\n  const responseData = item.json;\n  \n  // Check if this response has a files array\n  if (!responseData.files || !Array.isArray(responseData.files)) {\n    console.log('Skipping item without files array');\n    continue;\n  }\n  \n  // Determine folder type based on which node this came from\n  // We need to check the pairedItem to see the source\n  const itemIndex = item.pairedItem?.item || 0;\n  \n  // First input (index 0) is Strategy, second (index 1) is Meetings\n  const folderType = itemIndex === 0 ? 'strategy' : 'meetings';\n  const parentFolderId = itemIndex === 0 ? \n    '1s9-s7MArqGiMnhw67vzpmtGWCMX5iqA6' : \n    '11yY2XNYWYwKnWg60_5LwwgocmV3dS-46';\n  \n  console.log(`Processing batch for folder_type: ${folderType}, files: ${responseData.files.length}`);\n  \n  // Process each file in the response\n  for (const fileData of responseData.files) {\n    const enhancedItem = {\n      file_id: fileData.id,\n      file_name: fileData.name,\n      mime_type: fileData.mimeType,\n      modified_time: fileData.modifiedTime,\n      web_view_link: fileData.webViewLink,\n      size: fileData.size,\n      team_id: teamId,\n      folder_type: folderType,\n      parent_folder_id: parentFolderId\n    };\n    \n    processedItems.push({\n      json: enhancedItem,\n      pairedItem: item.pairedItem\n    });\n  }\n}\n\nconsole.log(`Tagged ${processedItems.length} files with team metadata`);\n\nreturn processedItems;\n\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -592,
        -96
      ],
      "id": "ea771684-d045-43a8-8b79-a8e8136c21f3",
      "name": "Add Team Metadata"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO document_chunks_meetings (\n  content, title, document_date, batch_id, team_id, metadata, embedding\n) \nVALUES (\n  $1, $2, $3::timestamp, $4::uuid, $5::uuid, $6::jsonb, $7::vector\n) \nON CONFLICT ON CONSTRAINT document_chunks_pkey \nDO UPDATE SET \n  content = EXCLUDED.content, \n  title = EXCLUDED.title,\n  document_date = EXCLUDED.document_date,\n  batch_id = EXCLUDED.batch_id,\n  team_id = EXCLUDED.team_id,\n  metadata = EXCLUDED.metadata, \n  embedding = EXCLUDED.embedding, \n  updated_at = NOW() \nRETURNING id\n",
        "options": {
          "queryReplacement": "=={{ $json.content }}, {{ $json.title }}, {{ $json.document_date }}, {{ $json.batch_id }}, {{ $json.team_id }}, {{ $json.metadata }}, {{ $json.embedding }}"
        }
      },
      "id": "cce7cf4b-abac-4333-bd71-9cb1d874b7ba",
      "name": "Store Vector Chunks - Meetings",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [
        -192,
        144
      ],
      "credentials": {
        "postgres": {
          "id": "kEtmOjsypxatQPLu",
          "name": "Postgres RocketHub"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO document_chunks_strategy (\n  content, title, document_date, batch_id, team_id, metadata, embedding\n) \nVALUES (\n  $1, $2, $3::timestamp, $4::uuid, $5::uuid, $6::jsonb, $7::vector\n) \nON CONFLICT ON CONSTRAINT document_chunks_strategy_title_content_hash_key \nDO UPDATE SET \n  content = EXCLUDED.content, \n  title = EXCLUDED.title,\n  document_date = EXCLUDED.document_date,\n  batch_id = EXCLUDED.batch_id,\n  team_id = EXCLUDED.team_id,\n  metadata = EXCLUDED.metadata, \n  embedding = EXCLUDED.embedding, \n  updated_at = NOW() \nRETURNING id\n\n",
        "options": {
          "queryReplacement": "=={{ $json.content }}, {{ $json.title }}, {{ $json.document_date }}, {{ $json.batch_id }}, {{ $json.team_id }}, {{ $json.metadata }}, {{ $json.embedding }}"
        }
      },
      "id": "beeb61a8-a2bc-4b5c-84af-1740011869b5",
      "name": "Store Vector Chunks - Strategy",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [
        -352,
        240
      ],
      "credentials": {
        "postgres": {
          "id": "kEtmOjsypxatQPLu",
          "name": "Postgres RocketHub"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.folder_type }}",
                    "rightValue": "meetings",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "5d8de30b-1646-4cc3-bfc5-08dd54cbebc7"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Meetings"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "db5e6269-6ab0-4e36-ad7b-e8b343c83337",
                    "leftValue": "={{ $json.folder_type }}",
                    "rightValue": "strategy",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Strategy"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        -528,
        160
      ],
      "id": "db203069-1945-429c-84eb-d818681e3b47",
      "name": "Route by Folder Type"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        0,
        224
      ],
      "id": "27e9a2c3-9af7-46d0-a2d7-a19520a84690",
      "name": "Merge Storage Results"
    },
    {
      "parameters": {
        "jsCode": "const items = [];\n\n// Get the access token from the current loop iteration\nconst loopData = $('Loop Over Each Connection').item.json;\nconst accessToken = loopData.access_token;\n\nconsole.log(`Using access token from loop iteration for team: ${loopData.team_id}`);\n\nfor (const item of $input.all()) {\n  const fileId = item.json.file_id || item.json.id;\n  const fileName = item.json.file_name || item.json.name;\n  \n  try {\n    const response = await this.helpers.httpRequest({\n      method: 'GET',\n      url: `https://www.googleapis.com/drive/v3/files/${fileId}/export?mimeType=text/plain`,\n      headers: {\n        'Authorization': `Bearer ${accessToken}`\n      }\n    });\n    \n    items.push({\n      json: {\n        file_id: fileId,\n        file_name: fileName,\n        content: response\n      }\n    });\n    \n    console.log(`✓ Downloaded: ${fileName}`);\n  } catch (error) {\n    console.log(`✗ Failed to download ${fileName}: ${error.message}`);\n    items.push({\n      json: {\n        file_id: fileId,\n        file_name: fileName,\n        error: error.message\n      }\n    });\n  }\n}\n\nconsole.log(`Downloaded ${items.length} files`);\nreturn items;\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        336,
        -96
      ],
      "id": "c23aed76-02b1-41e9-aa3d-045862f97bcd",
      "name": "Download Document Content"
    },
    {
      "parameters": {
        "jsCode": "// Update last_sync_at for this connection\nconst storedCount = $input.all().length;\n\n// Safely get the loop iteration data\nlet connectionData;\ntry {\n  connectionData = $('Loop Over Each Connection').item.json;\n} catch (error) {\n  console.log('Could not access loop data, using fallback');\n  // Fallback: try to get from the input data\n  const inputData = $input.first().json;\n  connectionData = {\n    id: inputData.connection_id || 'unknown',\n    team_id: inputData.team_id || 'unknown',\n    user_id: inputData.user_id || 'unknown'\n  };\n}\n\nconsole.log(`Sync complete for connection ${connectionData.id}`);\nconsole.log(`Stored ${storedCount} chunks`);\nconsole.log(`Team: ${connectionData.team_id}`);\n\nreturn [{\n  json: {\n    connection_id: connectionData.id,\n    team_id: connectionData.team_id,\n    user_id: connectionData.user_id,\n    chunks_stored: storedCount,\n    sync_timestamp: new Date().toISOString()\n  }\n}];\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        176,
        224
      ],
      "id": "2ce7e73e-07e4-44a2-abda-a36ba12ffae9",
      "name": "Update Sync Status"
    },
    {
      "parameters": {
        "jsCode": "// Get input files from previous node\nconst inputFiles = $('Add Team Metadata').all();\n\nconsole.log(`=== FILTERING NEW FILES ===`);\nconsole.log(`Input files from Drive: ${inputFiles.length}`);\n\n// Get existing documents from the HTTP Request node\nconst existingDocuments = $input.all().map(item => item.json);\n\nconsole.log(`Existing files from documents table: ${existingDocuments.length}`);\n\n// Debug: Show first few source_ids\nif (existingDocuments.length > 0) {\n  console.log(`\\nFirst 3 existing source_ids:`);\n  existingDocuments.slice(0, 3).forEach(f => {\n    console.log(`  - ${f.source_id} (modified: ${f.source_modified_time})`);\n  });\n}\n\n// Create a map of existing files for fast lookup\nconst existingMap = new Map();\nfor (const doc of existingDocuments) {\n  if (doc.source_id && doc.source_modified_time) {\n    existingMap.set(doc.source_id, new Date(doc.source_modified_time));\n  } else if (doc.source_id) {\n    // File exists but no timestamp stored (old data) - mark for re-processing\n    existingMap.set(doc.source_id, new Date(0)); // epoch time, will always be older\n  }\n}\n\nconsole.log(`Built lookup map with ${existingMap.size} existing source_ids`);\n\nconst newFiles = [];\nconst skippedFiles = [];\n\nfor (const item of inputFiles) {\n  const fileId = item.json.file_id;\n  const fileName = item.json.file_name;\n  const modifiedTime = item.json.modified_time;\n  \n  if (!existingMap.has(fileId)) {\n    console.log(`✓ NEW: ${fileName}`);\n    newFiles.push(item);\n  } else {\n    const lastModified = existingMap.get(fileId);\n    const fileModified = new Date(modifiedTime);\n    \n    if (fileModified > lastModified) {\n      console.log(`✓ UPDATED: ${fileName} (Drive: ${modifiedTime}, DB: ${lastModified.toISOString()})`);\n      newFiles.push(item);\n    } else {\n      console.log(`✗ SKIP: ${fileName} (unchanged)`);\n      skippedFiles.push(fileName);\n    }\n  }\n}\n\nconsole.log(`\\n=== RESULTS ===`);\nconsole.log(`New/Updated: ${newFiles.length}`);\nconsole.log(`Skipped: ${skippedFiles.length}`);\n\nif (newFiles.length === 0) {\n  console.log(`No new files to process - ending workflow`);\n  return [];\n}\n\nreturn newFiles;\n\n\n\n\n\n\n\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -208,
        -96
      ],
      "id": "ef2330a9-b3ce-459a-ad83-7781062e9a87",
      "name": "Filter New Files Only"
    },
    {
      "parameters": {
        "url": "https://poquwzvcleazbbdelcsh.supabase.co/rest/v1/documents",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "=team_id",
              "value": "=eq.{{ $('Loop Over Each Connection').item.json.team_id }}"
            },
            {
              "name": "source_type",
              "value": "eq.google_drive"
            },
            {
              "name": "select",
              "value": "source_id,source_modified_time"
            }
          ]
        },
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        -400,
        -96
      ],
      "id": "419a150a-9976-4a86-ac50-6f5e236eae13",
      "name": "Get Existing Files from DB",
      "credentials": {
        "supabaseApi": {
          "id": "6SAgSR5kLIGxGnI7",
          "name": "Supabase RocketHub"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Enhanced Content Classification": {
      "main": [
        [
          {
            "node": "Fast Hash Deduplication",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fast Hash Deduplication": {
      "main": [
        [
          {
            "node": "Download Document Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Documents": {
      "main": [
        [
          {
            "node": "Store Documents (UPSERT)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Chunk Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Documents (UPSERT)": {
      "main": [
        [
          {
            "node": "Success Metrics & Logging",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Vector Chunks - FINAL": {
      "main": [
        [
          {
            "node": "Route by Folder Type",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunk Content": {
      "main": [
        [
          {
            "node": "Generate OpenAI Embeddings1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate OpenAI Embeddings1": {
      "main": [
        [
          {
            "node": "Prepare Vector Chunks - FINAL",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "1 Hour": {
      "main": [
        [
          {
            "node": "Get Active Drive Connections",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Metadata": {
      "main": [
        [
          {
            "node": "Prepare Documents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Each Connection": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Get Files from Meetings Folder",
            "type": "main",
            "index": 0
          },
          {
            "node": "Get Files from Strategy Folder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Active Drive Connections": {
      "main": [
        [
          {
            "node": "Loop Over Each Connection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Files from Strategy Folder": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Files from Meetings Folder": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Add Team Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add Team Metadata": {
      "main": [
        [
          {
            "node": "Get Existing Files from DB",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Vector Chunks - Meetings": {
      "main": [
        [
          {
            "node": "Merge Storage Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route by Folder Type": {
      "main": [
        [
          {
            "node": "Store Vector Chunks - Meetings",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Store Vector Chunks - Strategy",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Vector Chunks - Strategy": {
      "main": [
        [
          {
            "node": "Merge Storage Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Storage Results": {
      "main": [
        [
          {
            "node": "Update Sync Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Document Content": {
      "main": [
        [
          {
            "node": "Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Sync Status": {
      "main": [
        [
          {
            "node": "Success Metrics & Logging",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter New Files Only": {
      "main": [
        [
          {
            "node": "Enhanced Content Classification",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Existing Files from DB": {
      "main": [
        [
          {
            "node": "Filter New Files Only",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "b6ddaa1a-c23f-4bb3-bee5-da65a16f2518",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "339010dd32d635dc12d1b22611396aba8fa80f3c41d9792b7d3b5098ba3bdda1"
  },
  "id": "h71aBw6dTxmzQzpk",
  "tags": []
}